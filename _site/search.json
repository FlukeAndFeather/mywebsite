[
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "I developed and taught jese4sci to address both scientific and pedagogical challenges. The jese4sci curriculum contained the essential software engineering skills that facilitate open science, like version control and documentation (see course map below). Because most students come in with different experience levels and goals, I designed the course to be self-directed and mastery-oriented, which allowed students to move at the pace and focus on the material best suited to their growth. Here’s an example lesson and assignment from the validation track on GitHub.\n\n\n\nFig 2: jese4sci course map"
  },
  {
    "objectID": "teaching.html#the-carpentries",
    "href": "teaching.html#the-carpentries",
    "title": "Teaching",
    "section": "The Carpentries",
    "text": "The Carpentries\nI’m a certified Carpentries instructor since 2019. I’ve taught Software and Data Carpentry workshops in-person and online for the Stanford Libraries and other other organizations."
  },
  {
    "objectID": "teaching.html#research-mentorship",
    "href": "teaching.html#research-mentorship",
    "title": "Teaching",
    "section": "Research Mentorship",
    "text": "Research Mentorship\nI’m passionate about sharing my data skills with other scientists to help them develop their own abilities and make their research more impactful. I’ve mentored scientists at all career stages, from undergraduate and graduate students to post-docs and faculty. These efforts supported publications in The Journal of Experimental Biology, Nature Communications, and Current Biology. If you’d like to develop your data science skills and have a research project that you want to be more open and reproducible, please contact me!"
  },
  {
    "objectID": "teaching.html#tutorials",
    "href": "teaching.html#tutorials",
    "title": "Teaching",
    "section": "Tutorials",
    "text": "Tutorials\nI make tutorials for R and data science workshops. You’re welcome to repurpose these for your teaching.\n\nGit and GitHub\nSCRUBs Lesson for Friday March 17, 2023\nSCRUBs Lesson for Friday January 27, 2023"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Animal-borne sensors, like GPS and accelerometers, allow remote observation of animal behavior and physiology. As these devices (bio-loggers) accumulate more and more sensors sampling at ever higher frequencies, the deluge of data becomes impossible to interpret with traditional tools. In my research, I develop new methods and software for the analysis and visualization of bio-logging data, with an emphasis on open and reproducible science practices. This page highlights my recent research and future directions."
  },
  {
    "objectID": "research.html#physiology",
    "href": "research.html#physiology",
    "title": "Research",
    "section": "Physiology",
    "text": "Physiology\n\n\n\n\n\n\nFig 3: A ballistocardiogram detects heart beats in motion data\n\n\n\n\nThe rumbling of a whale’s heart beat produces a physical waveform (a ballistocardiogram, or BCG), analogous to the more widely known electrocardiogram. I developed a method for extracting the BCG from standard bio-logging sensors (Czapanskiy et al. 2022), advancing our ability to monitor the physiological responses of endangered species to disturbances. I published the BCG method as a research compendium, meaning the data, code, and manuscript are all linked together in an R package available on GitHub."
  },
  {
    "objectID": "research.html#behavior",
    "href": "research.html#behavior",
    "title": "Research",
    "section": "Behavior",
    "text": "Behavior\n\n\n\n\n\n\nFig 4: Interactive inspection of Stickleback behavioral predictions\n\n\n\n\nWe can now observe extremely fine-scale behaviors with new high-resolution, multi-sensor bio-logging devices. Animal behavior scientists use accelerometers, microphones, and other sensors to identify individual behavioral events such as feeding and social interactions. Manually annotating behaviors in bio-logging data is a critical bottleneck and we lack computational tools for automating the process. I developed a machine learning pipeline, Stickleback, that uses time series classification algorithms to train a behavior detection model. Available in R and Python, currently in review at the Journal of Open Source Software."
  },
  {
    "objectID": "research.html#cyberinfrastructure",
    "href": "research.html#cyberinfrastructure",
    "title": "Research",
    "section": "Cyberinfrastructure",
    "text": "Cyberinfrastructure\nLike many new types of data, bio-logging lacks common tools and data standards (i.e., cyberinfrastructure). In the absence of these norms, scientists struggle to share and re-use data and code. I analyzed these challenges in bio-logging and described a future cyberinfrastructure solution based on successful efforts in other fields (Czapanskiy and Beltran 2022). My current research includes developing these tools and standards for bio-logging data, as well as educational resources to help bio-logging scientists make their science open and reproducible."
  },
  {
    "objectID": "posts/2023-03-17-intro-reticulate/index.html",
    "href": "posts/2023-03-17-intro-reticulate/index.html",
    "title": "Python and R together with reticulate",
    "section": "",
    "text": "Use R and Python together! Note: this lesson is for reticulate specifically. It’s not a Python lesson. But if you don’t know Python you should still be able to follow along with a friend."
  },
  {
    "objectID": "posts/2023-03-17-intro-reticulate/index.html#setup",
    "href": "posts/2023-03-17-intro-reticulate/index.html#setup",
    "title": "Python and R together with reticulate",
    "section": "Setup",
    "text": "Setup\nCreate an RStudio project, then create a Quarto document.\n\nInstall Python\nSo many ways. Too many ways! Here’s one. Do this from the R console.\n\ninstall.packages(\"reticulate\")\nreticulate::install_miniconda()\n\n\n\nCreate a virtual environment\nYou likely keep all your installed R packages in one library. The standard practice in Python is to create separate environments for projects instead. Conda helps us do that. Still in the console!\n\nreticulate::conda_create(\n  \"intro-reticulate\", \n  packages = c(\"jupyter\", \"numpy\", \"pandas\", \"scikit-learn\")\n)\nreticulate::use_condaenv(\"intro-reticulate\")\nreticulate::py_config() # Are you in the right place?\n\nWe just created a Conda environment and installed some useful Python packages. jupyter is the Python equivalent to knitr, numpy lets you work with numbers, pandas lets you work with data frames, and scikit-learn is for machine learning."
  },
  {
    "objectID": "posts/2023-03-17-intro-reticulate/index.html#tidy-tuesday",
    "href": "posts/2023-03-17-intro-reticulate/index.html#tidy-tuesday",
    "title": "Python and R together with reticulate",
    "section": "Tidy Tuesday",
    "text": "Tidy Tuesday\nLearn reticulate with a Tidy Tuesday exercise. Specifically Numbats.\n\nLoad the data\nWe can do that with R. In your Quarto document, create an R code chunk and download the Tidy Tuesday data.\n\n# install.packages(\"tidytuesdayR\")\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.7     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nnumbats_tidytuesday <- tidytuesdayR::tt_load(2023, week = 10)\n\n--- Compiling #TidyTuesday Information for 2023-03-07 ----\n\n\n--- There is 1 file available ---\n\n\n--- Starting Download ---\n\n\n\n    Downloading file 1 of 1: `numbats.csv`\n\n\n--- Download complete ---\n\nnumbats <- numbats_tidytuesday$numbats\nnumbats\n\n# A tibble: 805 × 16\n   decimalLatitude decimalLongitude eventDate           scientificName       \n             <dbl>            <dbl> <dttm>              <chr>                \n 1           -37.6             146. NA                  Myrmecobius fasciatus\n 2           -35.1             150. 2014-06-05 02:00:00 Myrmecobius fasciatus\n 3           -35               118. NA                  Myrmecobius fasciatus\n 4           -34.7             118. NA                  Myrmecobius fasciatus\n 5           -34.6             117. NA                  Myrmecobius fasciatus\n 6           -34.6             117. NA                  Myrmecobius fasciatus\n 7           -34.6             118. NA                  Myrmecobius fasciatus\n 8           -34.6             117. NA                  Myrmecobius fasciatus\n 9           -34.6             117. NA                  Myrmecobius fasciatus\n10           -34.6             117. NA                  Myrmecobius fasciatus\n# … with 795 more rows, and 12 more variables: taxonConceptID <chr>,\n#   recordID <chr>, dataResourceName <chr>, year <dbl>, month <chr>,\n#   wday <chr>, hour <dbl>, day <date>, dryandra <lgl>, prcp <dbl>, tmax <dbl>,\n#   tmin <dbl>\n\n\n\n\nNumbat circadian rhythms\nWere numbats sighted during the day or at night? Create another R chunk and categorize sighting time of day into day and night. The numbers look pretty even! But could environmental covariates influence that?\n\nnumbats <- numbats %>% \n  mutate(is_day = hour >= 6 & hour <= 18) %>% \n  drop_na(is_day, prcp, tmax)\ncount(numbats, is_day)\n\n# A tibble: 2 × 2\n  is_day     n\n  <lgl>  <int>\n1 FALSE     31\n2 TRUE      26\n\n\n\n\nR to Python\nLet’s use Python to figure out if precipitation and temperature affects the likelihood of seeing numbats at night. Create a Python code chunk.\n\n# This is like \"library()\" in R\nfrom sklearn.linear_model import LogisticRegression\n# Use `r.___` to access R objects\nenviro = r.numbats[[\"prcp\", \"tmax\"]]\nis_day = r.numbats[\"is_day\"]\n# Fit a classifier (clf)\nclf = LogisticRegression(random_state=0).fit(enviro, is_day)\n\nWell done! You just fit a classifier in Python to data you loaded and cleaned with R. That’s pretty cool! Let’s make some predictions on a reference grid.\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.utils.extmath import cartesian\n\n# The precipitation and temperature values we want to make predictions for\nprcp = np.arange(r.numbats[\"prcp\"].min(), r.numbats[\"prcp\"].max(), 0.1)\ntmax = np.arange(r.numbats[\"tmax\"].min(), r.numbats[\"tmax\"].max(), 0.2)\n# All combinations of prcp and tmax\nref_grid = pd.DataFrame(cartesian((prcp, tmax)), columns=[\"prcp\", \"tmax\"])\n# Predict the probability of \"is_day\". predict_proba() returns two columns,\n# p(!is_day) and p(is_day). Remember `[:, 1]` gets the *second* column \n# because Python uses 0-indexing\nref_grid[\"is_day\"] = clf.predict_proba(ref_grid)[:, 1]\nref_grid\n\n       prcp  tmax    is_day\n0       0.0  13.7  0.837053\n1       0.0  13.9  0.832279\n2       0.0  14.1  0.827395\n3       0.0  14.3  0.822400\n4       0.0  14.5  0.817291\n...     ...   ...       ...\n14701  11.3  38.5  0.000025\n14702  11.3  38.7  0.000024\n14703  11.3  38.9  0.000024\n14704  11.3  39.1  0.000023\n14705  11.3  39.3  0.000022\n\n[14706 rows x 3 columns]\n\n\n\n\nPython to R\nNow we’ll use R to visualize the model predictions generated in Python. Make another R code chunk.\n\nlibrary(reticulate)\n\n# Use py$____ to get python objects\npredict_prcp <- py$ref_grid %>% \n  # For each precipitation value, get the prediction at the median tmax\n  group_by(prcp) %>% \n  summarize(is_day = is_day[tmax = median(numbats$tmax)])\n\nnumbats %>% \n  mutate(is_day = as.numeric(is_day)) %>% \n  ggplot(aes(prcp, is_day)) +\n  geom_point() +\n  geom_line(data = predict_prcp) +\n  theme_classic()\n\n\n\n\nIs this a bad model? You know it! But that’s not the point."
  },
  {
    "objectID": "posts/2023-03-17-intro-reticulate/index.html#wrap-up",
    "href": "posts/2023-03-17-intro-reticulate/index.html#wrap-up",
    "title": "Python and R together with reticulate",
    "section": "Wrap up",
    "text": "Wrap up\n\nThe reticulate package connects R and Python\nPython installations are a lot more variable (and tricky!) than R\nYou can use both R and Python code, sharing data, in Quarto documents\nR -> Python with r.___\nPython -> R with py$___ (must library(reticulate) first!)"
  },
  {
    "objectID": "posts/2023-04-11-renew-pat/index.html",
    "href": "posts/2023-04-11-renew-pat/index.html",
    "title": "Renewing a GitHub PAT",
    "section": "",
    "text": "Generate a new token by calling usethis::create_github_token() from your R console (e.g., in RStudio). This launches GitHub in your browser. Sign in if necessary.\nYou should be at the “New personal access token” page. Change the Note to “RSTUDIO” or something similar. I like to set the Expiration to 90 days. Don’t change any of the check boxes. Scroll to the bottom and click the green “Generate token” button.\n\n\nIf you get an error saying “Note has already been taken”, call your token something else, like RSTUDIO2.\n\nYou should now see your list of tokens. The top one should be highlighted in green and look like a long string of random characters. Copy the whole thing using the copy icon just to the right of it.\n\nIf you encountered the error in step 2, use this opportunity to delete your expired “RSTUDIO” token.\n\nBack to RStudio. Again at the console, call gitcreds::gitcreds_set(). Notice you don’t give the function call any arguments, just hit enter.\n\nYou should see a prompt asking what to do with your current credentials. Choose “Replace these credentials”.\nPaste your token at the “Enter new password or token” prompt and hit enter.\n\nThat should do it!"
  },
  {
    "objectID": "posts/2023-03-09-osfr-data/index.html",
    "href": "posts/2023-03-09-osfr-data/index.html",
    "title": "Uploading data to OSF in R",
    "section": "",
    "text": "How do we keep our data and code in-sync while an analysis is in progress? This came up for me recently when my laptop went down1. All my code was in a GitHub repo, but the data were scattered across a couple Google Drive folders shared with me by collaborators. Although (Tierney and Ram 2020) give excellent advice for how to link the two after an analysis is complete and heading to publication, what should I do for a work in progress when the data are too large for GitHub or can’t be shared publicly yet?\nI’m using this as an opportunity to explore the Open Science Framework (OSF) and see if I should incorporate it into my workflow. I created a new project (private for now) and linked it to my GitHub repo. Then I tried uploading my data, which are in nested directories, and learned you can only upload files through the OSF interface, not a whole directory structure.\nNaturally I turned to R. Here’s what worked for me."
  },
  {
    "objectID": "posts/2023-03-09-osfr-data/index.html#connect-to-osf",
    "href": "posts/2023-03-09-osfr-data/index.html#connect-to-osf",
    "title": "Uploading data to OSF in R",
    "section": "Connect to OSF",
    "text": "Connect to OSF\nWe’re using the osfr package for this task. Thanks ROpenSci! The authentication vignette does a good job explaining how to get a personal access token (PAT). You can create an .Renviron file in your project repository and add your PAT with this code. Remember to replace [YOUR OSF PAT] with your actual OSF PAT!\n\nfile.create(\".Renviron\")\nwriteLines(\"OSF_PAT=[YOUR OSF PAT]\", \".Renviron\")\n\nAfter you restart your R session, you should be able to access your OSF projects."
  },
  {
    "objectID": "posts/2023-03-09-osfr-data/index.html#retrieve-your-node",
    "href": "posts/2023-03-09-osfr-data/index.html#retrieve-your-node",
    "title": "Uploading data to OSF in R",
    "section": "Retrieve your node",
    "text": "Retrieve your node\nYour OSF project is a “node” and the data files and directories within it are its child nodes. To upload files, you need a handle to the right directory. I made a directory called “data” in my OSF storage, where I’m going to upload everything.\n\nlibrary(osfr)\n\nAutomatically registered OSF personal access token\n\n# Retrieve the Antarctic Winter Communities project node\nantwincomm_prj <- osf_retrieve_node(\"https://osf.io/hwnvy/\")\n# Sanity check the project and file structure\nantwincomm_prj\n\n# A tibble: 1 × 3\n  name                                                 id    meta            \n  <chr>                                                <chr> <list>          \n1 Antarctic Peninsula Marine Winter Predator Community hwnvy <named list [3]>\n\nosf_ls_files(antwincomm_prj)\n\n# A tibble: 1 × 3\n  name  id                       meta            \n  <chr> <chr>                    <list>          \n1 data  6407ba51e25636042723251c <named list [3]>\n\n# Retreive the \"data\" node\nantwincomm_files <- osf_ls_files(antwincomm_prj)\nantwincomm_data <- antwincomm_files[antwincomm_files$name == \"data\"]"
  },
  {
    "objectID": "posts/2023-03-09-osfr-data/index.html#upload-directory",
    "href": "posts/2023-03-09-osfr-data/index.html#upload-directory",
    "title": "Uploading data to OSF in R",
    "section": "Upload directory",
    "text": "Upload directory\nOnce you have the handle to your data directory then osf_upload() will do the rest. Tell it to include subdirectories with recurse and, if you have a lot of files, set progress to TRUE so you can keep an eye on it.\n\nlocal_data <- \"path/to/your/data/here\"\nosf_upload(antwincomm_data, local_data, recurse = TRUE, progress = TRUE)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Max Czapanskiy",
    "section": "",
    "text": "My work advances ecological data science at multiple scales. I teach scientists how to use software engineering principles to make the most of their data, I develop tools for visualizing and analyzing big data, and I advocate for open science practices and policies.\nCurrently, I’m a postdoctoral scholar with NOAA’s Southwest Fisheries Science Center and UC Santa Cruz’s Ocean Sciences Department. In this role, I’m developing new software and publishing data to support marine resource management in California and the Antarctic. During my graduate studies, I created and taught a course called Just Enough Software Engineering (for Scientists) for the Stanford Biosciences Program. I also developed novel computational methods for deciphering biological signals in animal-borne sensor data (featured in Vox)."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Max Czapanskiy",
    "section": "Education",
    "text": "Education\nStanford University | Stanford, CA\nPhD in Biology | 2022\nSan Francisco State University | San Francisco, CA\nMS in Geographic Information Science | 2018\nColumbia University | New York, NY\nBS in Computer Science | 2014"
  },
  {
    "objectID": "pubs.html",
    "href": "pubs.html",
    "title": "Publications",
    "section": "",
    "text": "This publications list is generated programmatically from .bib files. Expand the folded code to see how!\n\nCode\n# Format a publication's author list\nformat_authors <- function(authors) {\n  # Split authors' names (First MI Last or First Last)\n  authors_split <- stringr::str_split(authors, \" \")\n  # Format as Last, FI. or Last, FI.MI.\n  authors_formatted <- purrr::map_chr(\n    authors_split,\n    function(parts) {\n      if (length(parts) == 3) {\n        sprintf(\"%s, %s.%s.\", \n                parts[3], \n                substr(parts[1], 1, 1), \n                substr(parts[2], 1, 1))\n      } else {\n        sprintf(\"%s, %s.\", \n                parts[2], \n                substr(parts[1], 1, 1))\n      }\n    }\n  )\n  # Shorten long author lists\n  if (length(authors_formatted) > 7) {\n    authors_short <- c(authors_formatted[1:5], \n                       \"...\", \n                       authors_formatted[length(authors_formatted)])\n  } else {\n    authors_short <- authors_formatted\n  }\n  # Make my name bold\n  authors_short[authors_short == \"Czapanskiy, M.F.\"] <- \"<strong>Czapanskiy, M.F.</strong>\"\n  # Concatenate\n  paste(authors_short, collapse = \", \")\n}\n\n# Find path to PDF file\nfind_pdf <- function(authors, year, title) {\n  lead_author <- stringr::str_extract(authors[1], \"[^ ]+$\")\n  title_short <- title |>\n    stringr::str_replace_all(\"[^a-zA-Z \\\\-]\", \"\") |>\n    substr(1, 30)\n  pdf_pattern <- glue::glue(\"{lead_author}.*- {year} - {title_short}\")\n  dir(here::here(\"assets\", \"papers\"), \n      pattern = pdf_pattern,\n      ignore.case = TRUE) |>\n    (\\(pdf) file.path(\"assets\", \"papers\", pdf))()\n}\n\n# Read bib file\npubs <- bib2df::bib2df(\"assets/works.bib\") |>\n  # Retain relevant fields and format author list\n  dplyr::transmute(\n    authors = purrr::map_chr(AUTHOR, format_authors),\n    title = TITLE,\n    journal = JOURNAL,\n    year = YEAR,\n    pdf = purrr::pmap_chr(list(AUTHOR, YEAR, TITLE), find_pdf)\n  ) |>\n  # Format in HTML. Markdown doesn't support reverse ordered lists??\n  dplyr::mutate(\n    pub_html = glue::glue(\"<li>{authors}. ({year}). {title}. <em>{journal}</em>. <a href=\\\"{pdf}\\\" target=\\\"_blank\\\">PDF</a></li>\")\n  ) |>\n  dplyr::pull(pub_html)\n# Reverse ordered list\nc(\n  \"<ol reversed>\",\n  pubs,\n  \"</ol>\"\n) |>\n  cat()\n\n\n\nKahane-Rapport, S.R., Czapanskiy, M.F., Fahlbusch, J.A., Friedlaender, A.S., Calambokidis, J., …, Savoca, M.S.. (2022). Field measurements reveal exposure risk to microplastic ingestion by filter-feeding megafauna. Nature Communications. PDF\n\n\nGough, W.T., Cade, D.E., Czapanskiy, M.F., Potvin, J., Fish, F.E., …, Goldbogen, J.A.. (2022). Fast and furious: energetic tradeoffs and scaling of high-speed foraging in rorqual whales. Integrative Organismal Biology. PDF\n\n\nFahlbusch, J.A., Czapanskiy, M.F., Calambokidis, J., Cade, D.E., Abrahms, B., Hazen, E.L., Goldbogen, J.A.. (2022). Blue whales increase feeding rates at fine-scale ocean features. Proceedings of the Royal Society B. PDF\n\n\nNazario, E.C., Cade, D.E., Bierlich, K., Czapanskiy, M.F., Goldbogen, J.A., …, Friedlaender, A.S.. (2022). Baleen whale inhalation variability revealed using animal-borne video tags. PeerJ. PDF\n\n\nCzapanskiy, M.F., Beltran, R.S.. (2022). How reproducibility will accelerate discovery through collaboration in physio-logging. Frontiers in Physiology. PDF\n\n\nCzapanskiy, M.F., Ponganis, P.J., Fahlbusch, J.A., Schmitt, T.L., Goldbogen, J.A.. (2022). An accelerometer-derived ballistocardiogram method for detecting heartrates in free-ranging marine mammals. Journal of Exp. Bio.. PDF\n\n\nBeltran, R.S., Yuen, A.L., Condit, R., Robinson, P.W., Czapanskiy, M.F., Crocker, D.E., Costa, D.P.. (2022). Elephant seals time their long-distance migrations using a map sense. Current Biology. PDF\n\n\nSegre, P.S., Gough, W.T., Roualdes, E.A., Cade, D.E., Czapanskiy, M.F., …, Goldbogen, J.A.. (2022). Scaling of maneuvering performance in baleen whales: larger whales outperform expectations. Journal of Exp. Bio.. PDF\n\n\nCade, D.E., Gough, W.T., Czapanskiy, M.F., Fahlbusch, J.A., Kahane-Rapport, S.R., …, Goldbogen, J.A.. (2021). Tools for integrating inertial sensor data with video bio-loggers, including estimation of animal orientation, motion, and position. Animal Biotelemetry. PDF\n\n\nSavoca, M.S., Czapanskiy, M.F., Kahane-Rapport, S.R., Gough, W.T., Fahlbusch, J.A., …, Goldbogen, J.A.. (2021). Baleen whale prey consumption based on high-resolution foraging measurements. Nature. PDF\n\n\nCzapanskiy, M.F., Savoca, M.S., Gough, W.T., Segre, P.S., Wisniewska, D.M., Cade, D.E., Goldbogen, J.A.. (2021). Modelling short-term energetic costs of sonar disturbance to cetaceans using high-resolution foraging data. Journal of Applied Ecology. PDF\n\n\nGough, W.T., Smith, H.J., Savoca, M.S., Czapanskiy, M.F., Fish, F.E., …, Goldbogen, J.A.. (2021). Scaling of oscillatory kinematics and Froude efficiency in baleen whales. Journal of Exp. Bio.. PDF\n\n\nWilliams, C.L., Czapanskiy, M.F., John, J.S., Leger, J.S., Scadeng, M., Ponganis, P.J.. (2021). Cervical air sac oxygen profiles in diving emperor penguins: parabronchial ventilation and the respiratory oxygen store. Journal of Exp. Bio.. PDF\n\n\nGoldbogen, J.A., Cade, D.E., Wisniewska, D.M., Potvin, J., Segre, P.S., …, Pyenson, N.D.. (2019). Why whales are big but not bigger: Physiological drivers and ecological limits in the age of ocean giants. Science. PDF\n\n\nGoldbogen, J.A., Cade, D.E., Calambokidis, J., Czapanskiy, M.F., Fahlbusch, J., …, Ponganis, P.J.. (2019). Extreme bradycardia and tachycardia in the world’s largest animal. PNAS. PDF\n\n\nAdams, J., Felis, J.J., Czapanskiy, M.F., Carle, R., Hodum, P.. (2019). Diving behavior of Pink-footed Shearwaters rearing chicks on Isla Mocha, Chile. Marine Ornithology. PDF\n\n\nKelsey, E.C., Felis, J.J., Czapanskiy, M.F., Pereksta, D.M., Adams, J.. (2018). Collision and displacement vulnerability to offshore wind energy infrastructure among marine birds of the Pacific Outer Continental Shelf. Journal of Env. Mgmt.. PDF"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Renewing a GitHub PAT\n\n\n\nR\n\n\ngit\n\n\nGitHub\n\n\n\nWhat to do when your GitHub personal access token (PAT) expires.\n\n\n\nMax Czapanskiy\n\n\nApr 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython and R together with reticulate\n\n\n\nR\n\n\nPython\n\n\nreticulate\n\n\nSCRUBs\n\n\n\nIntro to reticulate lesson for SCRUBs\n\n\n\nMax Czapanskiy\n\n\nMar 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUploading data to OSF in R\n\n\n\nR\n\n\nOSF\n\n\nreproducibility\n\n\n\nI’m learning to navigate the Open Science Framework (OSF), but ran into issues uploading a directory to my project. Here’s how I did it in R.\n\n\n\nMax Czapanskiy\n\n\nMar 9, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tutorials/git-and-github.html",
    "href": "tutorials/git-and-github.html",
    "title": "Git and GitHub",
    "section": "",
    "text": "SCRUBs Lesson Friday January 27, 2023"
  },
  {
    "objectID": "tutorials/git-and-github.html#pre-lesson-recap",
    "href": "tutorials/git-and-github.html#pre-lesson-recap",
    "title": "Git and GitHub",
    "section": "Pre-lesson recap",
    "text": "Pre-lesson recap\nBefore today’s lesson, you should have:\n\nFamiliarized yourself with the basics of Git and GitHub by reading Bryan 2018 (PDF on SCRUBs Drive)\nInstalled Git\nConnected RStudio to GitHub"
  },
  {
    "objectID": "tutorials/git-and-github.html#todays-agenda",
    "href": "tutorials/git-and-github.html#todays-agenda",
    "title": "Git and GitHub",
    "section": "Today’s agenda",
    "text": "Today’s agenda\nThe goal for today’s lesson is to get you just enough information to begin incorporating version control into your workflow. In order, we’ll cover:\n\nRStudio projects\nUsing Git\nBlowing it up and starting over\nBonus: sharing your work with GitHub Pages"
  },
  {
    "objectID": "tutorials/git-and-github.html#rstudio-projects",
    "href": "tutorials/git-and-github.html#rstudio-projects",
    "title": "Git and GitHub",
    "section": "RStudio projects",
    "text": "RStudio projects\nYou don’t have to use a project to use version control, but it sure does make it a lot easier. For more info about projects, see the R for Data Science chapter. Now let’s create an example RStudio project and connect it to GitHub. The preferred method for this is “New project, GitHub first”. See Happy Git with R for other options, but I suggest sticking with this one.\n\nCreate a GitHub repo\n\nGo to github.com\nClick the green “New” button to create a new repository\nCall it “myrepo” and click the green “Create repository” button\n\nCopy your repository link. It should be: https://github.com/[username]/myrepo.git.\n\n\n\n\nCreate an RStudio project with your repo\nCongratulations - you’ve created a Git repository! But right now it only lives on GitHub’s server. Let’s bring it down to your computer (clone your repo, in Git lingo).\n\nOpen RStudio\nFile > New Project > Version Control\n\nChoose Git for your version control then paste your repository link.\n\nYou now have a local copy of your repository that you can use for data analysis. A few things you should see in RStudio now:\n\n\nThe Git pane is where you’ll make Git do things. This is RStudio’s way of helping us avoid the command line and we’re very grateful for that.\nYour project name should now be visible in the top-right corner. Among other things, this means you’ll never have to call setwd() ever again. All R commands will execute relative to your project’s directory. You have no idea the number of problems this will help you avoid. Git aside, it’s reason enough to use projects.\nYou’ve got some new files.\n\nA directory called “.git”. NEVER TOUCH THIS. Forget it exists. Seriously.\nA text file called .gitignore. This is how you tell Git to ignore certain files, like sensitive data or very large files that are too big for GitHub.\nA project file called myrepo.Rproj. This is how RStudio knows you have a project. It’ll just hang out and make your life easier, you don’t have to do anything with it.\n\n\n\n\nProject do’s and don’ts (don’t’s?)\n\nNo nesting. Never put a project inside of another one. You want a flat hierarchy. Think Kansas: flatter than a pancake.\nCloud storage can cause headaches. If you use Drive, Box, or another service for syncing files you should probably put your projects somewhere else, like a local or external hard drive. Cloud sync software creates hidden files and modifies existing files in unpredictable ways that can make projects and version control puke all over themselves at random intervals. That said, if it’s your only choice, go for it. Then send me an email if you get an error message.\n\n\n\nRecap\nCongrats, you created a Git repository and turned it into an RStudio project on your local machine. But if you go back to GitHub and check out your repository, it will still look empty. In the next section, you’ll learn how to update your repository. But first, call an instructor over and show them your progress."
  },
  {
    "objectID": "tutorials/git-and-github.html#using-git",
    "href": "tutorials/git-and-github.html#using-git",
    "title": "Git and GitHub",
    "section": "Using Git",
    "text": "Using Git\nTL;DR: You’ll use commit and push for 85% of your version control needs.\n\nMake some changes\nGit tracks your changes. So let’s make some changes for Git to track.\n\nCreate a Quarto file. We have a lesson on Quarto later this quarter. Consider this a quick taste. In the Files pane, click on New Blank File > Quarto Doc. Call it “myquarto.qmd”.\n\nAdd the following text to your Quarto document and save it.\n---\ntitle: My Quarto Document\nformat: html\n---\n\nThis is a Quarto document. It combines text, code, and outputs like figures.\n\nLet's pretend @fig-boring was way more interesting.\n\n\n```{r}\n#| label: fig-boring\n#| fig-cap: A boring figure\n\nx <- -5:5\ny <- x^2\nplot(x, y, type = \"l\")\n```\nYou’ll understand what all this means after the Quarto lesson. For now, just know you’re creating a dynamic HTML document with a bit of text and a figure.\n\n\n\ncommit your changes\n\nSwitch over to your Git pane. You should have three changed files waiting for you.\n\nCheck the box for all three files (in the “Staged” column). The orange “?” will turn into a green “A”, indicating you’re adding these files to the repo.\nClick the Commit button in the Git pane. The commit window will appear, showing you the diff, or the changes you made. Every commit has to have a commit message. Enter “Initial commit” and hit the “Commit” button.\nYour Git pane should now be empty. This means all your changes have been tracked locally.\n\ncommit is a local operation! It tracks things just on your machine. Now let’s sync it up with GitHub.\n\n\npush your commits\nThis one is easy. Click Push in the Git pane.\nHead back over to GitHub in your browser. Refresh the page with your repository. It should now look like this:\n\nYour local repository (on your machine) and your remote repository (on GitHub) are now in sync. This serves as valuable back up and makes sharing easy!\n\n\nRecap\n\ncommit creates a local check point of your recently created, modified, and deleted files.\npush syncs your local commits to your remote repository on GitHub.\nCall an instructor over so they can see your repo on GitHub."
  },
  {
    "objectID": "tutorials/git-and-github.html#blowing-it-up-and-starting-over",
    "href": "tutorials/git-and-github.html#blowing-it-up-and-starting-over",
    "title": "Git and GitHub",
    "section": "Blowing it up and starting over",
    "text": "Blowing it up and starting over\nAt some point you’ll need to create another local copy of your repository (clone it from GitHub). Maybe you’re working on another computer, or you’re sharing your code with a collaborator, or Git did something weird and you need to blow it up and start over. Version control takes a very scary thing (re-creating your work from the ground up) and makes it easy.\n\nBlow it all up. By which I mean, delete your local files. First, close RStudio. Then delete the directory holding your project/repo. If it was in ~/Documents/GitHub/myrepo/, then delete the myrepo/ directory.\nclone it anew. Open RStudio. Create a new repository from version control as you did before.\n\nThis is one of the most valuable features of using version control. You can confidently make changes, experiment, and tinker secure in the knowledge you can always return to an earlier version."
  },
  {
    "objectID": "tutorials/git-and-github.html#sharing-your-work-with-github-pages",
    "href": "tutorials/git-and-github.html#sharing-your-work-with-github-pages",
    "title": "Git and GitHub",
    "section": "Sharing your work with GitHub Pages",
    "text": "Sharing your work with GitHub Pages\nWe’re going to wrap up today’s lesson with one of my favorite GitHub features: Pages. GitHub gives each repository it’s own website. Quarto and its predecessor, RMarkdown, can turn your work into HTML pages. By combining these two, you have a fantastic way of sharing your work with your collaborators.\n\nCreate an HTML page\n\nOpen the “myrepo” project in RStudio\nOpen myquarto.qmd\nClick “Render” at the top of the editing pane.\n\nThis should create myquarto.html and a directory called myquarto_files.\nYou just made some changes! Commit them, push them to GitHub, and check the website to make sure they show up.\n\n\nCreate a landing page in Markdown\nTo use GitHub pages you’ll need a landing page. We’ll make one in Markdown. If this is your first time with Markdown don’t worry, it’s easy.\n\nIn the Files pane, create a new blank text file and call it “index.md”. Make sure it’s not index.md.txt.\nAdd some text to index.md explaining your project. E.g. “This project is how I’m learning Git and GitHub.”\nAdd a link to your rendered Quarto document. In Markdown, links look like [text](url) . So add [My first Quarto document](myquarto.html) to index.md.\nCommit and push!\n\n\n\nTurn on GitHub Pages\nThis involves changing a setting on the GitHub website.\n\nIn your browser, go to your GitHub repo.\nGo to Settings > Pages.\nUnder Branch, change “None” to “master” and hit Save. You should get a ribbon at the top that says “GitHub Pages source saved”.\nSwitch from the Settings tab to Actions. You’ll see jobs listed including “build” and “deploy”. When they’re complete (green checkmarks), navigate to [your_username].github.io/myrepo.\n\nThis is a pretty trivial example, but it’s hopefully enough to get you started. For a fully featured example, check out Blue Whales and Lagrangian Features. My colleague, James Fahlbusch, used GitHub Pages to share an R Markdown report containing the analyses and results for the first chapter of his dissertation with his co-authors and advisor. The R Markdown document eventually became the Supplemental Material for his manuscript published in Proceedings B. This is a great way to facilitate collaborations and can even make the publishing process easier!\n\n\nRecap\n\nGitHub has a built-in features to help your projects have a web presence\nPages let you share your repo as a website\nCombining Pages with literate programming (Quarto or R Markdown) is a great way to use GitHub for collaboration."
  },
  {
    "objectID": "tutorials/git-and-github.html#lesson-recap",
    "href": "tutorials/git-and-github.html#lesson-recap",
    "title": "Git and GitHub",
    "section": "Lesson recap",
    "text": "Lesson recap\n\nGit and GitHub do have a learning curve, but they help you keep your analyses organized and safe.\nUsing RStudio projects helps you integrate version control into your normal workflow (and they have other benefits too, like better file paths).\nThere are a lot of Git commands, most only usable from the command line, but you’ll get most of the benefits just from using commit and push.\nOnce you start using Git and GitHub, you’ll have access to a lot of the tools and features built on top of them. GitHub Pages are a good example, but that’s only scratching the surface."
  },
  {
    "objectID": "tutorials/git-and-github.html#resources",
    "href": "tutorials/git-and-github.html#resources",
    "title": "Git and GitHub",
    "section": "Resources",
    "text": "Resources\n\nHappy Git With R\nR 4 Data Science"
  }
]